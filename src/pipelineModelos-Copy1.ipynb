{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python version: 3.5.2\n",
      "IPython version: 6.2.1\n",
      "numpy version: 1.13.3\n",
      "pandas version: 0.21.0\n",
      "scikit-learn version: 0.19.1\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import IPython\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn as sk\n",
    "\n",
    "print ('Python version: %s.%s.%s' % sys.version_info[:3])\n",
    "print ('IPython version:', IPython.__version__)\n",
    "print ('numpy version:', np.__version__)\n",
    "print ('pandas version:', pd.__version__)\n",
    "print ('scikit-learn version:', sk.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>VisitNumber</th>\n",
       "      <th>TripType</th>\n",
       "      <th>Weekday</th>\n",
       "      <th>Upc</th>\n",
       "      <th>ScanCount</th>\n",
       "      <th>DepartmentDescription</th>\n",
       "      <th>FinelineNumber</th>\n",
       "      <th>numItems</th>\n",
       "      <th>num_purchased</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10</td>\n",
       "      <td>8</td>\n",
       "      <td>friday</td>\n",
       "      <td>6414410235</td>\n",
       "      <td>1</td>\n",
       "      <td>dsd grocery</td>\n",
       "      <td>2008</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10</td>\n",
       "      <td>8</td>\n",
       "      <td>friday</td>\n",
       "      <td>2800053970</td>\n",
       "      <td>1</td>\n",
       "      <td>candy, tobacco, cookies</td>\n",
       "      <td>115</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10</td>\n",
       "      <td>8</td>\n",
       "      <td>friday</td>\n",
       "      <td>7794800902</td>\n",
       "      <td>1</td>\n",
       "      <td>dsd grocery</td>\n",
       "      <td>7950</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>100</td>\n",
       "      <td>37</td>\n",
       "      <td>friday</td>\n",
       "      <td>4383</td>\n",
       "      <td>1</td>\n",
       "      <td>produce</td>\n",
       "      <td>3102</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1000</td>\n",
       "      <td>9</td>\n",
       "      <td>friday</td>\n",
       "      <td>32878550911</td>\n",
       "      <td>1</td>\n",
       "      <td>infant consumable hardlines</td>\n",
       "      <td>2009</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  VisitNumber TripType Weekday          Upc  ScanCount  \\\n",
       "0          10        8  friday   6414410235          1   \n",
       "1          10        8  friday   2800053970          1   \n",
       "2          10        8  friday   7794800902          1   \n",
       "3         100       37  friday         4383          1   \n",
       "4        1000        9  friday  32878550911          1   \n",
       "\n",
       "         DepartmentDescription FinelineNumber  numItems  num_purchased  \n",
       "0                  dsd grocery           2008         3              3  \n",
       "1      candy, tobacco, cookies            115         3              3  \n",
       "2                  dsd grocery           7950         3              3  \n",
       "3                      produce           3102         1              1  \n",
       "4  infant consumable hardlines           2009         1              1  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#leyendo datos creados con Rstudio\n",
    "import feather\n",
    "walmart = feather.read_dataframe('../data/transformed_malo.feather')\n",
    "walmart.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  VisitNumber TripType  numItems  num_purchased  Weekday_friday  \\\n",
      "0          10        8         3              3               1   \n",
      "1          10        8         3              3               1   \n",
      "2          10        8         3              3               1   \n",
      "\n",
      "   Weekday_monday  Weekday_saturday  Weekday_sunday  Weekday_thursday  \\\n",
      "0               0                 0               0                 0   \n",
      "1               0                 0               0                 0   \n",
      "2               0                 0               0                 0   \n",
      "\n",
      "   Weekday_tuesday               ...                \\\n",
      "0                0               ...                 \n",
      "1                0               ...                 \n",
      "2                0               ...                 \n",
      "\n",
      "   DepartmentDescription_seafood  DepartmentDescription_seasonal  \\\n",
      "0                              0                               0   \n",
      "1                              0                               0   \n",
      "2                              0                               0   \n",
      "\n",
      "   DepartmentDescription_service deli  DepartmentDescription_sheer hosiery  \\\n",
      "0                                   0                                    0   \n",
      "1                                   0                                    0   \n",
      "2                                   0                                    0   \n",
      "\n",
      "   DepartmentDescription_shoes  DepartmentDescription_sleepwear/foundations  \\\n",
      "0                            0                                            0   \n",
      "1                            0                                            0   \n",
      "2                            0                                            0   \n",
      "\n",
      "   DepartmentDescription_sporting goods  \\\n",
      "0                                     0   \n",
      "1                                     0   \n",
      "2                                     0   \n",
      "\n",
      "   DepartmentDescription_swimwear/outerwear  DepartmentDescription_toys  \\\n",
      "0                                         0                           0   \n",
      "1                                         0                           0   \n",
      "2                                         0                           0   \n",
      "\n",
      "   DepartmentDescription_wireless  \n",
      "0                               0  \n",
      "1                               0  \n",
      "2                               0  \n",
      "\n",
      "[3 rows x 80 columns]\n"
     ]
    }
   ],
   "source": [
    "data2 = pd.get_dummies(walmart, columns =['Weekday', 'DepartmentDescription'])\n",
    "columns = ['Upc', 'FinelineNumber', 'ScanCount']#, 'VisitNumber']\n",
    "data2.drop(columns, inplace=True, axis=1)\n",
    "print(data2.loc[data2['VisitNumber'] == '10'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VisitNumber    category\n",
      "TripType       category\n",
      "dtype: object\n",
      "  VisitNumber TripType\n",
      "0          10        8\n",
      "3         100       37\n",
      "4        1000        9\n",
      "5      100002        9\n",
      "6      100003      999\n",
      "(94247, 2)\n",
      "       VisitNumber TripType\n",
      "455272           5      999\n"
     ]
    }
   ],
   "source": [
    "aux = data2\n",
    "temp = data2[['VisitNumber','TripType']]\n",
    "temp = temp.drop_duplicates(subset=['VisitNumber'], keep='first')\n",
    "\n",
    "print(temp.dtypes)\n",
    "print(temp.head(5))\n",
    "print(temp.shape)\n",
    "\n",
    "print(temp[temp['VisitNumber'] == '5'])\n",
    "#columns = ['TripType'] #,  'numItems',  'num_purchased' ]#, 'VisitNumber']\n",
    "#aux.drop(columns, inplace=True, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(94247, 79)\n",
      "  VisitNumber  numItems  num_purchased  Weekday_friday  Weekday_monday  \\\n",
      "0           5       1.0           -1.0             1.0             0.0   \n",
      "\n",
      "   Weekday_saturday  Weekday_sunday  Weekday_thursday  Weekday_tuesday  \\\n",
      "0               0.0             0.0               0.0              0.0   \n",
      "\n",
      "   Weekday_wednesday               ...                \\\n",
      "0                0.0               ...                 \n",
      "\n",
      "   DepartmentDescription_seafood  DepartmentDescription_seasonal  \\\n",
      "0                            0.0                             0.0   \n",
      "\n",
      "   DepartmentDescription_service deli  DepartmentDescription_sheer hosiery  \\\n",
      "0                                 0.0                                  0.0   \n",
      "\n",
      "   DepartmentDescription_shoes  DepartmentDescription_sleepwear/foundations  \\\n",
      "0                          0.0                                          0.0   \n",
      "\n",
      "   DepartmentDescription_sporting goods  \\\n",
      "0                                   0.0   \n",
      "\n",
      "   DepartmentDescription_swimwear/outerwear  DepartmentDescription_toys  \\\n",
      "0                                       0.0                         0.0   \n",
      "\n",
      "   DepartmentDescription_wireless  \n",
      "0                             0.0  \n",
      "\n",
      "[1 rows x 79 columns]\n"
     ]
    }
   ],
   "source": [
    "aux = aux.groupby([\"VisitNumber\"]).mean().reset_index()\n",
    "aux = aux.dropna(axis=0, how='any')\n",
    "print(aux.shape)\n",
    "#print(aux.columns.values)\n",
    "print(aux[aux['VisitNumber'] == '5'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(94247, 79)\n",
      "(94247, 2)\n",
      "(94247, 80)\n"
     ]
    }
   ],
   "source": [
    "print(aux.shape)\n",
    "print(temp.shape)\n",
    "df = temp.join(aux.set_index('VisitNumber'), on='VisitNumber', how=\"right\")\n",
    "#df = aux.merge(temp, on=['VisitNumber'], how='left', indicator=True)\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  VisitNumber TripType  numItems  num_purchased  Weekday_friday  \\\n",
      "0          10        8       3.0            3.0             1.0   \n",
      "3         100       37       1.0            1.0             1.0   \n",
      "\n",
      "   Weekday_monday  Weekday_saturday  Weekday_sunday  Weekday_thursday  \\\n",
      "0             0.0               0.0             0.0               0.0   \n",
      "3             0.0               0.0             0.0               0.0   \n",
      "\n",
      "   Weekday_tuesday               ...                \\\n",
      "0              0.0               ...                 \n",
      "3              0.0               ...                 \n",
      "\n",
      "   DepartmentDescription_seafood  DepartmentDescription_seasonal  \\\n",
      "0                            0.0                             0.0   \n",
      "3                            0.0                             0.0   \n",
      "\n",
      "   DepartmentDescription_service deli  DepartmentDescription_sheer hosiery  \\\n",
      "0                                 0.0                                  0.0   \n",
      "3                                 0.0                                  0.0   \n",
      "\n",
      "   DepartmentDescription_shoes  DepartmentDescription_sleepwear/foundations  \\\n",
      "0                          0.0                                          0.0   \n",
      "3                          0.0                                          0.0   \n",
      "\n",
      "   DepartmentDescription_sporting goods  \\\n",
      "0                                   0.0   \n",
      "3                                   0.0   \n",
      "\n",
      "   DepartmentDescription_swimwear/outerwear  DepartmentDescription_toys  \\\n",
      "0                                       0.0                         0.0   \n",
      "3                                       0.0                         0.0   \n",
      "\n",
      "   DepartmentDescription_wireless  \n",
      "0                             0.0  \n",
      "3                             0.0  \n",
      "\n",
      "[2 rows x 80 columns]\n",
      "VisitNumber                                      0\n",
      "TripType                                         0\n",
      "numItems                                         0\n",
      "num_purchased                                    0\n",
      "Weekday_friday                                   0\n",
      "Weekday_monday                                   0\n",
      "Weekday_saturday                                 0\n",
      "Weekday_sunday                                   0\n",
      "Weekday_thursday                                 0\n",
      "Weekday_tuesday                                  0\n",
      "Weekday_wednesday                                0\n",
      "DepartmentDescription_1-hr photo                 0\n",
      "DepartmentDescription_accessories                0\n",
      "DepartmentDescription_automotive                 0\n",
      "DepartmentDescription_bakery                     0\n",
      "DepartmentDescription_bath and shower            0\n",
      "DepartmentDescription_beauty                     0\n",
      "DepartmentDescription_bedding                    0\n",
      "DepartmentDescription_books and magazines        0\n",
      "DepartmentDescription_boys wear                  0\n",
      "DepartmentDescription_bras & shapewear           0\n",
      "DepartmentDescription_cameras and supplies       0\n",
      "DepartmentDescription_candy, tobacco, cookies    0\n",
      "DepartmentDescription_celebration                0\n",
      "DepartmentDescription_comm bread                 0\n",
      "DepartmentDescription_concept stores             0\n",
      "DepartmentDescription_cook and dine              0\n",
      "DepartmentDescription_dairy                      0\n",
      "DepartmentDescription_dsd grocery                0\n",
      "DepartmentDescription_electronics                0\n",
      "                                                ..\n",
      "DepartmentDescription_lawn and garden            0\n",
      "DepartmentDescription_liquor,wine,beer           0\n",
      "DepartmentDescription_meat - fresh & frozen      0\n",
      "DepartmentDescription_media and gaming           0\n",
      "DepartmentDescription_menswear                   0\n",
      "DepartmentDescription_mens wear                  0\n",
      "DepartmentDescription_null                       0\n",
      "DepartmentDescription_office supplies            0\n",
      "DepartmentDescription_optical - frames           0\n",
      "DepartmentDescription_optical - lenses           0\n",
      "DepartmentDescription_other departments          0\n",
      "DepartmentDescription_paint and accessories      0\n",
      "DepartmentDescription_personal care              0\n",
      "DepartmentDescription_pets and supplies          0\n",
      "DepartmentDescription_pharmacy otc               0\n",
      "DepartmentDescription_pharmacy rx                0\n",
      "DepartmentDescription_players and electronics    0\n",
      "DepartmentDescription_plus and maternity         0\n",
      "DepartmentDescription_pre packed deli            0\n",
      "DepartmentDescription_produce                    0\n",
      "DepartmentDescription_seafood                    0\n",
      "DepartmentDescription_seasonal                   0\n",
      "DepartmentDescription_service deli               0\n",
      "DepartmentDescription_sheer hosiery              0\n",
      "DepartmentDescription_shoes                      0\n",
      "DepartmentDescription_sleepwear/foundations      0\n",
      "DepartmentDescription_sporting goods             0\n",
      "DepartmentDescription_swimwear/outerwear         0\n",
      "DepartmentDescription_toys                       0\n",
      "DepartmentDescription_wireless                   0\n",
      "Length: 80, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df.head(2))\n",
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[35 23 36 36 37 10 25 29 32 37]\n",
      "(94247,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/farid/.pyenv/versions/3.5.2/lib/python3.5/site-packages/sklearn/preprocessing/label.py:111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "X = df.iloc[:, df.columns != 'TripType']\n",
    "y = df.iloc[:, df.columns=='TripType'] \n",
    "\n",
    "label_encoder = LabelEncoder()  ## Para convertir a enteros\n",
    "\n",
    "## Convertirmos a enteros, etc\n",
    "y = label_encoder.fit_transform(y)\n",
    "print(y[0:10],)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  9.57316614e+04  -5.87828831e+00  -6.10777228e-03  -1.59580659e-02\n",
      "    6.57810381e-01   5.66803025e-01   1.65573740e-02   1.37070315e-02\n",
      "    4.35610541e-03  -3.36614910e-01]\n",
      " [  9.56416614e+04  -8.69316137e+00  -2.66189519e-01  -2.56059685e-02\n",
      "    6.52868628e-01   5.63542652e-01   1.77362934e-02   1.12661969e-02\n",
      "    5.71819856e-04  -8.63365400e-02]]\n",
      "(94247, 10)\n"
     ]
    }
   ],
   "source": [
    "#Usando PCA\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pca = PCA(n_components=10)\n",
    "pca.fit(X)\n",
    "\n",
    "X = pca.transform(X)\n",
    "print(X[0:2,])\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/farid/.pyenv/versions/3.5.2/lib/python3.5/site-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n",
      "/home/farid/.pyenv/versions/3.5.2/lib/python3.5/site-packages/sklearn/grid_search.py:42: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. This module will be removed in 0.20.\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.cross_validation import StratifiedKFold, cross_val_score, train_test_split \n",
    "from sklearn.metrics import classification_report, f1_score, accuracy_score, confusion_matrix\n",
    "\n",
    "X_train, X_test, y_train, y_test = \\\n",
    "    train_test_split(X, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Magic Loop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[tutorial](http://www.codiply.com/blog/hyperparameter-grid-search-across-multiple-models-in-scikit-learn/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*First  dictionary:* models to be scored <br>\n",
    "*Second dictionary:* parameters for each model <br>\n",
    "*Fit:* returns a paremeter grid search with cross validation for each model and for the given data <br>\n",
    "*Score_summary:* returns a data_frame with a summary of the scores <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.grid_search import GridSearchCV\n",
    "\n",
    "class EstimatorSelectionHelper:\n",
    "    def __init__(self, models, params):\n",
    "        if not set(models.keys()).issubset(set(params.keys())):\n",
    "            missing_params = list(set(models.keys()) - set(params.keys()))\n",
    "            raise ValueError(\"Some estimators are missing parameters: %s\" % missing_params)\n",
    "        self.models = models\n",
    "        self.params = params\n",
    "        self.keys = models.keys()\n",
    "        self.grid_searches = {}\n",
    "    \n",
    "    def fit(self, X, y, cv=3, n_jobs=1, verbose=1, scoring=None, refit=True):\n",
    "        for key in self.keys:\n",
    "            print(\"Running GridSearchCV for %s.\" % key)\n",
    "            model = self.models[key]\n",
    "            params = self.params[key]\n",
    "            gs = GridSearchCV(model, \n",
    "                              params, \n",
    "                              cv=cv, \n",
    "                              n_jobs=n_jobs, \n",
    "                              verbose=verbose, \n",
    "                              scoring=scoring, \n",
    "                              refit=refit)\n",
    "            gs.fit(X,y)\n",
    "            self.grid_searches[key] = gs    \n",
    "    \n",
    "    def score_summary(self, sort_by='mean_score'):\n",
    "        def row(key, scores, params):\n",
    "            d = {\n",
    "                 'estimator': key,\n",
    "                 'min_score': min(scores),\n",
    "                 'max_score': max(scores),\n",
    "                 'mean_score': np.mean(scores),\n",
    "                 'std_score': np.std(scores),\n",
    "            }\n",
    "            return pd.Series({**params, **d})\n",
    "            #return pd.Series(dict(params.items() + d.items()))\n",
    "                      \n",
    "        rows = [row(k, gsc.cv_validation_scores, gsc.parameters) \n",
    "                for k in self.keys\n",
    "                for gsc in self.grid_searches[k].grid_scores_]\n",
    "        df = pd.concat(rows, axis=1).T.sort_values([sort_by], ascending=False)\n",
    "        \n",
    "        columns = ['estimator', 'min_score', 'mean_score', 'max_score', 'std_score']\n",
    "        columns = columns + [c for c in df.columns if c not in columns]\n",
    "        \n",
    "        return df[columns]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import (ExtraTreesClassifier, RandomForestClassifier, \n",
    "                              AdaBoostClassifier, GradientBoostingClassifier)\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import  LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "models1 = { \n",
    "    #'ExtraTreesClassifier': ExtraTreesClassifier(),\n",
    "    'RandomForestClassifier': RandomForestClassifier(),\n",
    "    #'AdaBoostClassifier': AdaBoostClassifier(),\n",
    "    #'GradientBoostingClassifier': GradientBoostingClassifier(),\n",
    "    #'LogisticRegression' : LogisticRegression(),\n",
    "    #'KNeighborsClassifier' : KNeighborsClassifier(),\n",
    "    #'NaiveBayes': MultinomialNB(),\n",
    "    #'SVC': SVC()\n",
    "}\n",
    "\n",
    "params1 = { \n",
    "    #'ExtraTreesClassifier': { 'n_estimators': [16, 32] },\n",
    "    'RandomForestClassifier': { 'n_estimators': [50,100], 'max_depth': [100, 200], 'max_features':['sqrt', 'log2'], 'min_samples_split': [10, 50] }#,\n",
    "    #'AdaBoostClassifier':  { 'n_estimators': [16, 32] },\n",
    "    #'GradientBoostingClassifier': { 'n_estimators': [16, 32], 'learning_rate': [0.8, 1.0] },\n",
    "    #'LogisticRegression' : { 'C' : [1, 1e3, 1e5] },\n",
    "    #'KNeighborsClassifier' : { 'n_neighbors' : [3,5] },\n",
    "    #'NaiveBayes' : { 'alpha' : [0.1, 0.001, 0.0001] },\n",
    "    #'SVC': [\n",
    "    #    {'kernel': ['linear'], 'C': [1, 10, 100]},\n",
    "    #    {'kernel': ['rbf'], 'C': [1, 10, 100], 'gamma': [0.001, 0.0001]},\n",
    "    #]\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running GridSearchCV for RandomForestClassifier.\n",
      "Fitting 3 folds for each of 2 candidates, totalling 6 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   6 out of   6 | elapsed:  1.8min remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done   6 out of   6 | elapsed:  1.8min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 13s, sys: 300 ms, total: 1min 14s\n",
      "Wall time: 3min 2s\n"
     ]
    }
   ],
   "source": [
    "helper1 = EstimatorSelectionHelper(models1, params1)\n",
    "%time helper1.fit(X_train, y_train, scoring='accuracy', n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>estimator</th>\n",
       "      <th>min_score</th>\n",
       "      <th>mean_score</th>\n",
       "      <th>max_score</th>\n",
       "      <th>std_score</th>\n",
       "      <th>max_depth</th>\n",
       "      <th>max_features</th>\n",
       "      <th>min_samples_split</th>\n",
       "      <th>n_estimators</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>0.504534</td>\n",
       "      <td>0.505007</td>\n",
       "      <td>0.505872</td>\n",
       "      <td>0.000612552</td>\n",
       "      <td>100</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>10</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>0.503223</td>\n",
       "      <td>0.504277</td>\n",
       "      <td>0.505076</td>\n",
       "      <td>0.000777796</td>\n",
       "      <td>100</td>\n",
       "      <td>log2</td>\n",
       "      <td>10</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                estimator min_score mean_score max_score    std_score  \\\n",
       "0  RandomForestClassifier  0.504534   0.505007  0.505872  0.000612552   \n",
       "1  RandomForestClassifier  0.503223   0.504277  0.505076  0.000777796   \n",
       "\n",
       "  max_depth max_features min_samples_split n_estimators  \n",
       "0       100         sqrt                10           50  \n",
       "1       100         log2                10           50  "
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "helper1.score_summary(sort_by='min_score')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Evaluating model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SVC(C=10, kernel='linear') #, gamma=0.001)\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "print(model.score(X_train, y_train))\n",
    "y_pred = model.predict(X_test)\n",
    "print (confusion_matrix(y_test, y_pred))\n",
    "print (classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ROC curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import cycle\n",
    "\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from scipy import interp\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "X = iris_df.iloc[:,0:4]\n",
    "y = iris_df.iloc[:,4]\n",
    "\n",
    "label_encoder = LabelEncoder()  ## Para convertir a enteros\n",
    "#one_hot_encoder = OneHotEncoder()\n",
    "\n",
    "## Convertirmos a enteros, i.e. setosa -> 0, etc\n",
    "y = label_encoder.fit_transform(y)\n",
    "\n",
    "# Binarize the output\n",
    "y = label_binarize(y, classes=[0, 1, 2])\n",
    "n_classes = y.shape[1]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.5,\n",
    "                                                    random_state=0)\n",
    "\n",
    "classifier = OneVsRestClassifier(SVC(C=10, kernel='linear', probability=True))\n",
    "y_score = classifier.fit(X_train, y_train).decision_function(X_test)\n",
    "\n",
    "print(y_test[0:10], y_score[0:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute ROC curve and ROC area for each class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_classes = label_binarize(y, classes=[0, 1, 2]).shape[1]\n",
    "\n",
    "fpr = dict()\n",
    "tpr = dict()\n",
    "roc_auc = dict()\n",
    "for i in range(n_classes):\n",
    "    fpr[i], tpr[i], _ = roc_curve(y_test[:, i], y_score[:, i])\n",
    "    roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "\n",
    "# Compute micro-average ROC curve and ROC area\n",
    "fpr[\"micro\"], tpr[\"micro\"], _ = roc_curve(y_test.ravel(), y_score.ravel())\n",
    "roc_auc[\"micro\"] = auc(fpr[\"micro\"], tpr[\"micro\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "lw = n_classes\n",
    "# Compute macro-average ROC curve and ROC area\n",
    "\n",
    "# First aggregate all false positive rates\n",
    "all_fpr = np.unique(np.concatenate([fpr[i] for i in range(n_classes)]))\n",
    "\n",
    "# Then interpolate all ROC curves at this points\n",
    "mean_tpr = np.zeros_like(all_fpr)\n",
    "for i in range(n_classes):\n",
    "    mean_tpr += interp(all_fpr, fpr[i], tpr[i])\n",
    "\n",
    "# Finally average it and compute AUC\n",
    "mean_tpr /= n_classes\n",
    "\n",
    "fpr[\"macro\"] = all_fpr\n",
    "tpr[\"macro\"] = mean_tpr\n",
    "roc_auc[\"macro\"] = auc(fpr[\"macro\"], tpr[\"macro\"])\n",
    "\n",
    "# Plot all ROC curves\n",
    "plt.figure()\n",
    "plt.plot(fpr[\"micro\"], tpr[\"micro\"],\n",
    "         label='micro-average ROC curve (area = {0:0.2f})'\n",
    "               ''.format(roc_auc[\"micro\"]),\n",
    "         color='deeppink', linestyle=':', linewidth=4)\n",
    "\n",
    "plt.plot(fpr[\"macro\"], tpr[\"macro\"],\n",
    "         label='macro-average ROC curve (area = {0:0.2f})'\n",
    "               ''.format(roc_auc[\"macro\"]),\n",
    "         color='navy', linestyle=':', linewidth=4)\n",
    "\n",
    "colors = cycle(['aqua', 'darkorange', 'cornflowerblue'])\n",
    "for i, color in zip(range(n_classes), colors):\n",
    "    plt.plot(fpr[i], tpr[i], color=color, lw=lw,\n",
    "             label='ROC curve of class {0} (area = {1:0.2f})'\n",
    "             ''.format(i, roc_auc[i]))\n",
    "\n",
    "plt.plot([0, 1], [0, 1], 'k--', lw=lw)\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Some extension of Receiver operating characteristic to multi-class')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Precision Vs Recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_precision_recall_n(y_true, y_prob, model_name):\n",
    "    from sklearn.metrics import precision_recall_curve\n",
    "    y_score = y_prob\n",
    "    precision_curve, recall_curve, pr_thresholds = precision_recall_curve(y_true, y_score)\n",
    "    precision_curve = precision_curve[:-1]\n",
    "    recall_curve = recall_curve[:-1]\n",
    "    pct_above_per_thresh = []\n",
    "    number_scored = len(y_score)\n",
    "    for value in pr_thresholds:\n",
    "        num_above_thresh = len(y_score[y_score>=value])\n",
    "        pct_above_thresh = num_above_thresh / float(number_scored)\n",
    "        pct_above_per_thresh.append(pct_above_thresh)\n",
    "    pct_above_per_thresh = np.array(pct_above_per_thresh)\n",
    "    plt.clf()\n",
    "    fig, ax1 = plt.subplots()\n",
    "    ax1.plot(pct_above_per_thresh, precision_curve, 'b')\n",
    "    ax1.set_xlabel('percent of population')\n",
    "    ax1.set_ylabel('precision', color='b')\n",
    "    ax2 = ax1.twinx()\n",
    "    ax2.plot(pct_above_per_thresh, recall_curve, 'r')\n",
    "    ax2.set_ylabel('recall', color='r')\n",
    "\n",
    "    name = model_name\n",
    "    plt.title(name)\n",
    "    #plt.savefig(name)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## no for multiclass labels\n",
    "\n",
    "plot_precision_recall_n(y_test[:,0], y_score[:,0], classifier)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# From scikit learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.metrics import average_precision_score\n",
    "\n",
    "# For each class\n",
    "precision = dict()\n",
    "recall = dict()\n",
    "average_precision = dict()\n",
    "for i in range(n_classes):\n",
    "    precision[i], recall[i], _ = precision_recall_curve(y_test[:, i],\n",
    "                                                        y_score[:, i])\n",
    "    average_precision[i] = average_precision_score(y_test[:, i], y_score[:, i])\n",
    "\n",
    "# A \"micro-average\": quantifying score on all classes jointly\n",
    "precision[\"micro\"], recall[\"micro\"], _ = precision_recall_curve(y_test.ravel(),\n",
    "    y_score.ravel())\n",
    "average_precision[\"micro\"] = average_precision_score(y_test, y_score,\n",
    "                                                     average=\"micro\")\n",
    "print('Average precision score, micro-averaged over all classes: {0:0.2f}'\n",
    "      .format(average_precision[\"micro\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Micro-average precision-recall curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.step(recall['micro'], precision['micro'], color='b', alpha=0.2,\n",
    "         where='post')\n",
    "plt.fill_between(recall[\"micro\"], precision[\"micro\"], step='post', alpha=0.2,\n",
    "                 color='b')\n",
    "\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.title(\n",
    "    'Average precision score, micro-averaged over all classes: AP={0:0.2f}'\n",
    "    .format(average_precision[\"micro\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import cycle\n",
    "# setup plot details\n",
    "colors = cycle(['navy', 'turquoise', 'darkorange', 'cornflowerblue', 'teal'])\n",
    "\n",
    "plt.figure(figsize=(7, 8))\n",
    "f_scores = np.linspace(0.2, 0.8, num=4)\n",
    "lines = []\n",
    "labels = []\n",
    "for f_score in f_scores:\n",
    "    x = np.linspace(0.01, 1)\n",
    "    y = f_score * x / (2 * x - f_score)\n",
    "    l, = plt.plot(x[y >= 0], y[y >= 0], color='gray', alpha=0.2)\n",
    "    plt.annotate('f1={0:0.1f}'.format(f_score), xy=(0.9, y[45] + 0.02))\n",
    "\n",
    "lines.append(l)\n",
    "labels.append('iso-f1 curves')\n",
    "l, = plt.plot(recall[\"micro\"], precision[\"micro\"], color='gold', lw=2)\n",
    "lines.append(l)\n",
    "labels.append('micro-average Precision-recall (area = {0:0.2f})'\n",
    "              ''.format(average_precision[\"micro\"]))\n",
    "\n",
    "for i, color in zip(range(n_classes), colors):\n",
    "    l, = plt.plot(recall[i], precision[i], color=color, lw=2)\n",
    "    lines.append(l)\n",
    "    labels.append('Precision-recall for class {0} (area = {1:0.2f})'\n",
    "                  ''.format(i, average_precision[i]))\n",
    "\n",
    "fig = plt.gcf()\n",
    "fig.subplots_adjust(bottom=0.25)\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "plt.title('Extension of Precision-Recall curve to multi-class')\n",
    "plt.legend(lines, labels, loc=(0, -.38), prop=dict(size=14))\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
